-Si vamos a dibujar usando GLES, usaremos una GBM surface. Sus buffers vienen incluidos, y se va dibujando en uno o en otro, mira drmFlip() en el ejemplo
de GLES2D-KMS para entenderlo. Hay alguna sutileza como lo de eglSwapBuffers() y la función de lock buffer esa, pero está todo comentado en el código.
A SetCRTC le tendremos que pasar uno de los buffers, claro, ya que un CRTC es un combo de conector+videomode+buffer de scanout, que será el que esté
de front buffer en ese momento.

-En cambio, si queremos dibujar a piñón pixel a pixel, tenemos que usar DUMB BUFFERS. Lo mismo: a setCRTC habrá que pasarle un buffer, pero este buffer
lo creamos nosotros a mano con drmIoctl(drm.fd, DRM_IOCTL_MODE_CREATE_DUMB, &fbRequeriments) 
y con drmModeAddFB(drm.fd, drm.mode->hdisplay, drm.mode->vdisplay, 16, 16,  fbRequeriments.pitch, fbRequeriments.handle, &fb->fb_id), y luego
se lo pasaremos a setCRTC. (Vamos, uno de los buffers que hayamos creado).

*******OJO A ESTA PREGUNTA: NECESITAMOS HACER SETCRTC() PARA QUE EL PAGEFLIP FUNCIONE? TANTO SI USAMOS GLES COMO SI NO.

-¿Necesitamos llamar a drmModeSetCrtc() antes de poder hacer drmModePageFlip()? Porque el pageflip falla con error -22 si no
hemos llamado a SetCrtc antes...
EL ERROR -22 SIGNIFICA EINVAL, SIEMPRE. Si ves -22, es EINVAL, invalid argument.
Pues robert clark dice que, si no estamos SEGUROS de que el modo de vídeo actual es compatible con los buffers de la gbm surface sobre los que vamos a
hacer el pageflip, pues que sí, que necesitamos hacer el SetCrtc(): al hacerlo, ponemos como scanout buffer uno de los buffers que vamos a usar, con su
resolución, formato de color, etc, con lo que el modo físico cambia a uno compatible con los buffers en los que vamos a dibujar (usando GLES o no usando GLES)
y ya estamos SEGUROS de que el pageflip va a funcionar. Si lo queremos hacer SIN SetCrtc(), pues tenemos que asegurarnos de que nuestro modo de vídeo actual
es compatible con los buffers que vamos a usar, lo que puede ser complicado.

18:32 <robclark> well, if that is not enough to figure out, then you might need to add debug prints on kernel side to track down 
                 where it is returning -EINVAL..
18:33 <robclark> short version, *something* about the buffer you are trying to flip to is incompatible with buffer being scanned out, 
                 and so a full modeset is required instead of just a pageflip
18:33 <robclark> ie, do a setcrtc
18:34 <Vanfanel> hmmmmm... now I get it. I must change the scanout buffer because it's not compatible somehow with the GBM buffers I 
                 am trying to pageflip to, right?
18:34 <Vanfanel> I mean... the phisical video mode is not compatible with these buffers
18:34 <robclark> yes.. color format is likely problem, but isn't the only one
18:35 <Vanfanel> this is the kind of explanation I needed, Rob
18:35 <robclark> pageflip is *only* meant to flip between different buffers that have otherwise all same parameters
18:35 <robclark> (which is why everything does setcrtc first ;-))

Al fin de que coincidan los parámetros del modo actual (CRTC actual sin llamar a SetCrtc()) y los de los buffers de la GBM surface que vamos a usar,
vigila la llamada a gbm_surface_create() para ver qué le estás pasando a la creación de la superficie GBM, y si quieres también la creación de nuevos buffers
en drmModeAddFB(), que se crean a partir de los gbm_bo (gbm buffer objects), así:
locked_bo = gbm_surface_lock_front_buffer(gbm.surface); 		<---Aquí sacamos un BO de la surface
fb = drmFBGetFromBO(locked_bo);								<---Y aquí ya sacamos un fb que podemos usar, a partir del BO. No te compliques.

Para comprobar que coinciden el CRTC actual y los parámetros de gbm_surface_create(), fíjate en el CRTC que devuelve drmModeGetCrtc() (sin haber llamado a SetCrtc, obviamente)
y compáralo con los parámetros de gbm_surface_create().

Pero vamos, que lo más importante es que coincidan los parámetros del CRTC actual con los de  gbm_surface_create(), y drmModePageFlip() a un buffer
de la gbm surface debería funcionar.
Si no encuentras manera de que coincida, pues llama a SetCrtc(), no te de complejo, que no pasa nada y es como se hacen las cosas, y debería ir.


***********************************************************************************************************************************************
ESTE FICHERO SÓLO CUBRE HASTA LA INICIALIZACIÓN ESTÁTICA DE LOS OVERLAYS. 
PARA QUE EL OVERLAY VAYA CAMBIANDO DE FRAMEBUFFER, USAMOS ATOMIC PAGEFLIPPING: MIRAR EN NOTAS_ATOMIC.TXT PARA MÁS DETALLES.
***********************************************************************************************************************************************

--------GRAN BLOQUE DE KMS DIRECTAMENTE SIN USAR GBM SURFACES NI NADA Y USANDO OVERLAYS PARA ESCALAR-----------

-Para ver mensajes de debug de KMS/DRM
echo 31 > /sys/module/drm/parameters/debug
Limpiamos dmesg con dmesg -c como root.
Luego hacemos dmesg >> errors.txt y buscamos "Invalid" o el ioctl que ha fallado, SETPLANE o lo que sea.
En realidad lo mejor es buscar literalmente DRM_IOCTL_MODE_SETPLANE, y ver debajo qué error ha habido.

Si el programa nos devuelve un "Cannot allocate memory" en una llamada a drmModeAtomicCommit(), lo que tenemos que buscar es ENOMEM, que es el error -12, y nos
apacerecrá en el dmesg como -12 efectivamente. 

-Si estamos usando un modo de video de 32 bits y queremos que un plano nos escale un buffer de 16, no va a poder ser: los planos disponibles para el CRTC en uso serán todos con
formatos de 16 bits y por tanto tendremos que hacer un SetCrtc. Sin embargo, para escalar en un overlay un buffer de 32 bits si estamos en un modo de vídeo de 32 bits no hace falta
hacer un SetCrtc. De hecho, para testar los planos, modetest.c no hace un SetCrtc si le decimos que teste con un XR24 o un XB24, pero si intentamos que escale un RG16 nos dice que no
hay overlays libres para el CRTC en uso...lógico. Piensa que necesitas un modo de vídeo distinto si el pixel format del overlay es de 16 bits que si es de 32 bits: o sea, los modos de 16 bits son compatibles
con overlays con formatos de 16 bits (RG16 por ejemplo) y los modos de 32 bits son compatibles con overlays con formatos de 32 bits (XR24, XB24...)..

-Si el plano es primario, necesitamos que cubra todo el CRTC El plano 17 que tiene soporte RG16 es primario. Si nos da un error (en dmesg 
detallado, mira más arriba) que dice "Plane must cover entire CRTC" (debajo de SETPLANE que habremos buscado en el LOG) pues es eso: estás usando un plano primario y paśandole valores
crtc_w y crtc_h menores que los del modo físico del CRTC. 

-Cada conector usa un encoder, y cada encoder tiene un CRTC. Conseguido el conector, tenemos su CRTC de forma sencilla: drm.crtc_id = drm.encoder->crtc_id;
Y ese es el CRTC que usaremos. Así que, aunque podemos cambiar el modo de vídeo que está usando un CRTC, no podemos cambiar de CRTC a no ser que cambiemos de conector.
Así que si un plano no se puede usar con un CRTC (if (overlay->possible_crtcs & (1 << crtc_index))) entonces olvídate de ese plano si no cambias de conector físico...

-Los planos primarios no se pueden escalar: o sea, que tienen que cubrir el CRTC entero (el tamaño del plano tendrá que ser el del modo físico en uso) y encima no nos sirven para
escalar un buffer. Los planos que sí se pueden escalar se llaman overlays.

-A un plano primario le tienes que pasar, en drmModeSetPlane() las mismas dimensiones de entrada que de salida. No escala. No puedes coger un trozo de un buffer de 320x200 y que lo
pinte a pantalla completa. 
Además, no puedes crear ese plano con dimensiones distintas a las del modo físico del CRTC en uso.
Todo esto es para la función drmModeSetPlane(). Tú puedes crear los buffers del tamaño que quieras.
O sea, dicho de otro modo, si el plano es primario, los parámetros según el prototipo de drmModeSetPlane() de /usr/include/xf86drmMode.h tendrán las siguentes LIMITACIONES:
----uint32_t crtc_w, uint32_t crtc_h tienen que coincidir con el tamaño del modo físico de pantalla en uso, ya que un plano primario tiene que cubrir todo el CRTC, o sea, el modo físico que
está usando el CRTC ahora mismo.  Nosotros solemos llamar a estos parámetros plane_w y plane_h.
----uint32_t src_w, uint32_t src_h tienen que coincidir con el tamaño del modo físico de pantalla en uso, ya que un plano primario no se puede escalar, así que hay que usar las dimensiones del 
modo físico en uso como dimensiones del source.

-El plano primario es el plano primario y controla el CRTC, por eso no se puede escalar ni nada. Los otros planos, los que son escalables, se llaman overlays. Visto en:
 https://www.kernel.org/doc/htmldocs/drm/drm-kms-init.html

-CUIDADO con modetest.c!!! Para saber si un plano es primario o es un overlay (que puede escalar, que no tiene que cubrir todo el CRTC...) modetest.c nos dice
 type:
                flags: immutable enum
                enums: Overlay=0 Primary=1 Cursor=2
                value: 1
PUES BIEN: enums es el nombre y los POSIBLES valores del tipo de plano. value es el valor. Este es un plano de tipo 1.

-A nosotros sólo nos interesan los planos de tipo OVERLAY, que es el tipo definido como 0. Lo puedes ver en /usr/include/xf86drmMode.h

--PARA QUE EL OVERLAY VAYA CAMBIANDO DE FRAMEBUFFER, USAMOS ATOMIC PAGEFLIPPING: MIRAR EN NOTAS_ATOMIC.TXT PARA MÁS DETALLES.

***************************** NO HACE FALTA LLAMAR A drmModeSetCrtc()********************************************
-¿Cómo dibujo cuando uso overlays? Muy sencillo: creo el framebuffer (drmModeAddFB2()), lo mapeo (mmap) de manera que la puedo escribir en él, y luego se lo paso al
overlay. NO hay necesidad de hacer drmModeSetCrtc() para ajustar el scanout buffer ni nada de eso.
Con atomic modesetting (ver notas en otro fichero) vamos cambiando el buffer del cual lee un overlay.
***********************************************************************************************************************

Para cambiar el BPP, lo que hacemos es cambiar el bpp y el píxel format de los dumb buffers que creamos en modeset_create_fb(), y luego, al llamar a drmModeSetPlane(),
el plano toma el bpp y el píxel format del buffer del que va a leer.

En 2D-KMS, también habrá que hacer cambios en drmDraw() y en varios puntos de main.c para que pasemos a considerar 2 bytes por píxel en lugar de 4, pero funciona.

*************GLES SOBRE KMS/DRM: CÓMO CONSEGUIR BLOQUEAR HASTA QUE SE HAGA EL BUFFER SWAP PENDIENTE, PARA ASÍ TENER EL MINIMO INPUT LAG POSIBLE************

O sea, cómo entender e implementar max_swapchain = 2 en todas partes. NO TIENE SENTIDO PENSARLO COMO SISTEMA DE DOBLE BUFFER, PERO EL RESULTADO ES EL QUE ESPERAS,
ES DECIR, TENER EL MENOR INPUT LAG POSIBLE
CUANDO LO LEAS HASTA EL FINAL LO ENTENDERÁS.

Lo primero es tener separado en la cabeza el buffer swap de EGL (llamada a eglSwapBuffers()) del buffer swap de KMS/DRM (que se hace inmediatamente después, ya que la
implementación de eglSwapBuffers() sobre KMS/DRM no hace el swap buffers sobre la gbm surface internamente, y por eso lo tenemos que hacer nosotros a mano).

Si te fijas en RetroArch, en gfx/drivers_context/drm_ctx.c se hace esto en gfx_ctx_drm_swap_buffers(), que es UNA FUNCIÓN MUY INTERESANTE:

egl_swap_buffers(&drm->egl);								<---Pide el swapbuffers de EGL para empezar, pero el buffer que se esté usando en la GBM surface no cambia por hacer esto sólo.

waiting_for_flip = gfx_ctx_drm_queue_flip();				<---Ahí dentro es donde se llama a drmModePageFlip() para issue un flip, que se hará en el siguiente vsync.

// Triple-buffered page flips?
if (video_info->max_swapchain_images >= 3 &&			<---Si tenemos un max_swapchain igual o mayor que 3, Y ADEMÁS quedan buffers libres en la superficie GBM, se retorna y
    gbm_surface_has_free_buffers(g_gbm_surface))			se permite al programa principal loopear otra vez, renderizando otro fotograma y llegando aquí de nuevo... añadiendo
    return;															de este modo un fotograma de input lag.

gfx_ctx_drm_wait_flip(true);								<--Aquí hemos llegado si teníamos un max_swapchain menor que tres (2, por ejemplo) o si ya no quedaban buffers libres en
																     la surface GBM.  Esperamos a que se produzca el swap realmente, es decir, esperamos al vsync. De este modo, queda libre un
																     buffer de la surface GBM si ese era el problema, o en todo caso impedimos que el programa loopee otra vez, con lo que no metemos
																     ese frame extra de input lag. Esta función usa por dentro drm_wait_flip() y gbm_surface_release_buffer(), para esperar a vsync
																     y liberar el buffer respectivamente.

Así que siempre, EN CUALQUIER MIDDLEWARE QUE USE GLES SOBRE KMS/DRM, vamos a poder esperar a vsync tras hacer drmModePageFlip() y asegurarnos así de que no se usa un
"triple buffer". Quédate con la idea de que NOSOTROS NO CONTROLAMOS EL NÚMERO DE BUFFERS QUE SE CREAN PARA UNA GBM SURFACE, PERO SÍ PODEMOS CONTROLAR QUE
SE ESPERE TRAS ISSUAR UN FLIP, Y DE ESE MODO EL PROGRAMA NO LOOPEA HASTA QUE SE PRESENTA EL ÚLTIMO FRAME EN PANTALLA Y NOS AHORRAMOS UN FRAME
O LOS QUE SEAN (dependiendo del número de buffers que tenga la GBM SURFACE y por tanto las veces que se pueda retornar inmediatamente tras comprobar gbm_has_free_buffers())
DE INPUT LAG.

ADDENDUM: ¿Es esto extrapolable a EGL sobre Dispmanx? Debería serlo si se espera de algún modo tras eglSwapBuffers() hasta que se haga el buffer swap en el lado de dispmanx.
Quizá una secuencia "vc_dispmanx_update_start(), vc_dispmanx_update_submit()", dado que update_submit es síncrona, podría ayudar... pero no se sabe aún. La idea, en todo caso,
sería la misma.

